{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38ec38-b991-4466-9808-2cf49d547efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\PC/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Loss: 0.008766594933219221\n",
      "Epoch [2/150], Loss: 0.003647911751861165\n",
      "Epoch [3/150], Loss: 0.002264536985946892\n",
      "Epoch [4/150], Loss: 0.0029546834653790626\n",
      "Epoch [5/150], Loss: 0.001961795601713459\n",
      "Epoch [6/150], Loss: 0.001592508774633518\n",
      "Epoch [7/150], Loss: 0.0014271742894075672\n",
      "Epoch [8/150], Loss: 0.0013296161293066963\n",
      "Epoch [9/150], Loss: 0.0012959898233834207\n",
      "Epoch [10/150], Loss: 0.0012877529157479274\n",
      "Epoch [11/150], Loss: 0.0012579963376742886\n",
      "Epoch [12/150], Loss: 0.004961850970387783\n",
      "Epoch [13/150], Loss: 0.005982721283729963\n",
      "Epoch [14/150], Loss: 0.0039145649881162795\n",
      "Epoch [15/150], Loss: 0.002884825991463946\n",
      "Epoch [16/150], Loss: 0.002409445827452172\n",
      "Epoch [17/150], Loss: 0.0025151689717473323\n",
      "Epoch [18/150], Loss: 0.0021008617809384674\n",
      "Epoch [19/150], Loss: 0.0017119991274984546\n",
      "Epoch [20/150], Loss: 0.0015760602533288958\n",
      "Epoch [21/150], Loss: 0.0015074950582233248\n",
      "Epoch [22/150], Loss: 0.0014756279242765455\n",
      "Epoch [23/150], Loss: 0.004737704211924165\n",
      "Epoch [24/150], Loss: 0.002931139061251701\n",
      "Epoch [25/150], Loss: 0.002029284815318807\n",
      "Epoch [26/150], Loss: 0.001749628991044939\n",
      "Epoch [27/150], Loss: 0.001637532434381771\n",
      "Epoch [28/150], Loss: 0.0015103150672628376\n",
      "Epoch [29/150], Loss: 0.0014716316022615012\n",
      "Epoch [30/150], Loss: 0.002416547298884254\n",
      "Epoch [31/150], Loss: 0.0015417131226019213\n",
      "Epoch [32/150], Loss: 0.0014394015581219008\n",
      "Epoch [33/150], Loss: 0.001421556926659927\n",
      "Epoch [34/150], Loss: 0.0014312919674039576\n",
      "Epoch [35/150], Loss: 0.0016317100442040243\n",
      "Epoch [36/150], Loss: 0.0014311178714069288\n",
      "Epoch [37/150], Loss: 0.0013273511406751255\n",
      "Epoch [38/150], Loss: 0.0012855555174141778\n",
      "Epoch [39/150], Loss: 0.001251453450879597\n",
      "Epoch [40/150], Loss: 0.0012536956480530383\n",
      "Epoch [41/150], Loss: 0.001245003072989703\n",
      "Epoch [42/150], Loss: 0.0024198485247240915\n",
      "Epoch [43/150], Loss: 0.002011304715171176\n",
      "Epoch [44/150], Loss: 0.0014089819626119824\n",
      "Epoch [45/150], Loss: 0.0012852085835816588\n",
      "Epoch [46/150], Loss: 0.0012269002084206527\n",
      "Epoch [47/150], Loss: 0.0012003632687576729\n",
      "Epoch [48/150], Loss: 0.001228946159349811\n",
      "Epoch [49/150], Loss: 0.0011851380992944954\n",
      "Epoch [50/150], Loss: 0.0011499779532743043\n",
      "Epoch [51/150], Loss: 0.001137086280585198\n",
      "Epoch [52/150], Loss: 0.0011254556166404364\n",
      "Epoch [53/150], Loss: 0.0011730030267977853\n",
      "Epoch [54/150], Loss: 0.0030613652829420464\n",
      "Epoch [55/150], Loss: 0.0016632514511128584\n",
      "Epoch [56/150], Loss: 0.0013281243297981716\n",
      "Epoch [57/150], Loss: 0.0012330722657481125\n",
      "Epoch [58/150], Loss: 0.0012285688685795073\n",
      "Epoch [59/150], Loss: 0.0012264992514768058\n",
      "Epoch [60/150], Loss: 0.001168387291033775\n",
      "Epoch [61/150], Loss: 0.001135776419861056\n",
      "Epoch [62/150], Loss: 0.001118562058929769\n",
      "Epoch [63/150], Loss: 0.0011021102692355036\n",
      "Epoch [64/150], Loss: 0.001084303690926556\n",
      "Epoch [65/150], Loss: 0.0025478005405871248\n",
      "Epoch [66/150], Loss: 0.0016833684985376302\n",
      "Epoch [67/150], Loss: 0.0013281923510516992\n",
      "Epoch [68/150], Loss: 0.0012257481623958533\n",
      "Epoch [69/150], Loss: 0.0011431299710670533\n",
      "Epoch [70/150], Loss: 0.0010949228573509649\n",
      "Epoch [71/150], Loss: 0.0010889457988885653\n",
      "Epoch [72/150], Loss: 0.0014856803802404063\n",
      "Epoch [73/150], Loss: 0.0019661985969847517\n",
      "Epoch [74/150], Loss: 0.0012576173689060031\n",
      "Epoch [75/150], Loss: 0.0011373297688746676\n",
      "Epoch [76/150], Loss: 0.001094094062137772\n",
      "Epoch [77/150], Loss: 0.001066850728790684\n",
      "Epoch [78/150], Loss: 0.0010480842901482725\n",
      "Epoch [79/150], Loss: 0.0010342340715574546\n",
      "Epoch [80/150], Loss: 0.001036973313297726\n",
      "Epoch [81/150], Loss: 0.0010454817796355133\n",
      "Epoch [82/150], Loss: 0.001047511516319515\n",
      "Epoch [83/150], Loss: 0.0020477574068632426\n",
      "Epoch [84/150], Loss: 0.0015524818825464043\n",
      "Epoch [85/150], Loss: 0.0013260193851098482\n",
      "Epoch [86/150], Loss: 0.0012635312072781769\n",
      "Epoch [87/150], Loss: 0.0011469494529855579\n",
      "Epoch [88/150], Loss: 0.0012411980750915283\n",
      "Epoch [89/150], Loss: 0.0017034220772050052\n",
      "Epoch [90/150], Loss: 0.0011750831398115575\n",
      "Epoch [91/150], Loss: 0.001100057256899979\n",
      "Epoch [92/150], Loss: 0.0010662448539246311\n",
      "Epoch [93/150], Loss: 0.0010460726933637378\n",
      "Epoch [94/150], Loss: 0.0010457109584433987\n",
      "Epoch [95/150], Loss: 0.0010393936889227238\n",
      "Epoch [96/150], Loss: 0.0010470659559654602\n",
      "Epoch [97/150], Loss: 0.001102346943101041\n",
      "Epoch [98/150], Loss: 0.0011513106859870007\n",
      "Epoch [99/150], Loss: 0.0010944705991567734\n",
      "Epoch [100/150], Loss: 0.001048806662888262\n",
      "Epoch [101/150], Loss: 0.001030400048337564\n",
      "Epoch [102/150], Loss: 0.0010813973809008833\n",
      "Epoch [103/150], Loss: 0.0010257056478260008\n",
      "Epoch [104/150], Loss: 0.0020842641850127453\n",
      "Epoch [105/150], Loss: 0.0018157243692247377\n",
      "Epoch [106/150], Loss: 0.001261251876144178\n",
      "Epoch [107/150], Loss: 0.0011293464198751664\n",
      "Epoch [108/150], Loss: 0.0010760478340439746\n",
      "Epoch [109/150], Loss: 0.0010422244823002694\n",
      "Epoch [110/150], Loss: 0.001024739393578942\n",
      "Epoch [111/150], Loss: 0.0010111707720269385\n",
      "Epoch [112/150], Loss: 0.0009986863171010563\n",
      "Epoch [113/150], Loss: 0.0010279738175778417\n",
      "Epoch [114/150], Loss: 0.0011193360472920143\n",
      "Epoch [115/150], Loss: 0.0010750126602416575\n",
      "Epoch [116/150], Loss: 0.001019632566434516\n",
      "Epoch [117/150], Loss: 0.001001435745434698\n",
      "Epoch [118/150], Loss: 0.0010051509249529515\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\dpns-project\\train_deeplabv3.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m model_save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels/deeplabv3/deeplabv3_model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m deeplabv3_model()\n\u001b[1;32m----> 9\u001b[0m train(epochs, model_save_path, model, \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\dpns-project\\training.py:31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, model_save_path, model, flag)\u001b[0m\n\u001b[0;32m     29\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     30\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 31\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m], Loss: \u001b[39m\u001b[39m{\u001b[39;00mrunning_loss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_x)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m (epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from deeplabv3_model import deeplabv3_model\n",
    "from training import train\n",
    "\n",
    "epochs = 150\n",
    "model_save_path = 'models/deeplabv3/deeplabv3_model'\n",
    "\n",
    "model = deeplabv3_model()\n",
    "\n",
    "train(epochs, model_save_path, model, True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
